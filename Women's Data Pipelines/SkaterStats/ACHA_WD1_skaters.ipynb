{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03aa01a-f93b-4602-a0e9-67a4af777c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Jersey#               Name Pos   Division                       Team  GP  \\\n",
      "0          9       Loki Antonio   F   WD1 WMCH  WD1 Lindenwood University  21   \n",
      "1         14     Madison Teague   D   WD1 WMCH  WD1 Lindenwood University  21   \n",
      "2         17    Ardyn Hawryshko   F   WD1 WMCH  WD1 Lindenwood University  21   \n",
      "3         16      Tess McKerrow   F  WD1 CCWHA         WD1 Adrian College  22   \n",
      "4         13         Aria Groot   D   WD1 WMCH   WD1 McKendree University  20   \n",
      "..       ...                ...  ..        ...                        ...  ..   \n",
      "806       21  Tanna Christensen   D   WD1 WMCH     WD1 Midland University  19   \n",
      "807       76      Davanna Ditto   D   WD1 WMCH     WD1 Midland University  20   \n",
      "808       26   Kirsten Martinez   D   WD1 WMCH  WD1 Lindenwood University  21   \n",
      "809       16      Lauren Miller   F   WD1 WMCH  WD1 Lindenwood University  21   \n",
      "810        7      Hailey Putnam   D   WD1 WMCH   WD1 Maryville University  21   \n",
      "\n",
      "      G   A  PTS  Pt/G  PPG  SHG  GWG  SOGW  PIM  SH%  \n",
      "0    25  17   42  2.00    7    0    3     0   16  0.0  \n",
      "1     7  23   30  1.43    3    1    2     0   33  0.0  \n",
      "2    13  14   27  1.29    7    0    2     0    4  0.0  \n",
      "3     9  17   26  1.18    4    0    3     0   16  0.0  \n",
      "4     8  16   24  1.20    1    0    2     0    6  0.0  \n",
      "..   ..  ..  ...   ...  ...  ...  ...   ...  ...  ...  \n",
      "806   0   0    0  0.00    0    0    0     0    2  0.0  \n",
      "807   0   0    0  0.00    0    0    0     0    0  0.0  \n",
      "808   0   0    0  0.00    0    0    0     0   20  0.0  \n",
      "809   0   0    0  0.00    0    0    0     0    4  0.0  \n",
      "810   0   0    0  0.00    0    0    0     0    8  0.0  \n",
      "\n",
      "[811 rows x 16 columns]\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811 entries, 0 to 810\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Jersey#   783 non-null    Int64  \n",
      " 1   Name      811 non-null    object \n",
      " 2   Pos       811 non-null    object \n",
      " 3   Division  811 non-null    object \n",
      " 4   Team      811 non-null    object \n",
      " 5   GP        811 non-null    int64  \n",
      " 6   G         811 non-null    int64  \n",
      " 7   A         811 non-null    int64  \n",
      " 8   PTS       811 non-null    int64  \n",
      " 9   Pt/G      811 non-null    float64\n",
      " 10  PPG       811 non-null    int64  \n",
      " 11  SHG       783 non-null    Int64  \n",
      " 12  GWG       811 non-null    int64  \n",
      " 13  SOGW      811 non-null    int64  \n",
      " 14  PIM       783 non-null    Int64  \n",
      " 15  SH%       811 non-null    float64\n",
      "dtypes: Int64(3), float64(2), int64(7), object(4)\n",
      "memory usage: 103.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_acha_dynamic_stats():\n",
    "    firefox_options = Options()\n",
    "    firefox_options.add_argument(\"--headless\")  \n",
    "\n",
    "    geckodriver_path = #Choose the path to geckodriver.exe, for example: r\"C:\\Program Files\\GeckoDriver\\geckodriver.exe\"\n",
    "    service = Service(executable_path=geckodriver_path)\n",
    "\n",
    "    with webdriver.Firefox(service=service, options=firefox_options) as driver:\n",
    "        url = \"https://www.achahockey.org/stats/player-stats/all-teams/45?conference=11&division=-1&playertype=skater&position=skaters&rookie=no&sort=points&statstype=standard&page=1&league=1\"\n",
    "        driver.get(url)\n",
    "\n",
    "        all_data = []\n",
    "        \n",
    "        while True:\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"table\")))\n",
    "            \n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            table = soup.find('table')\n",
    "            if table:\n",
    "                rows = table.find_all('tr')\n",
    "                for i, row in enumerate(rows[1:], start=1):  \n",
    "                    cols = row.find_all('td')\n",
    "                    cols = [ele.text.strip() for i, ele in enumerate(cols) if i != 0 and i != 2 and i != len(cols) - 1]\n",
    "                    all_data.append(cols)\n",
    "\n",
    "            try:\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//a[contains(text(), 'Next')]\"))\n",
    "                )\n",
    "                next_button.click()\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "acha_dynamic_stats = scrape_acha_dynamic_stats()\n",
    "\n",
    "column_names = ['Jersey#', 'Name', 'Pos', 'Division', 'Team', 'GP', 'G', 'A', 'PTS', 'Pt/G', 'PPG', 'SHG', 'GWG', 'SOGW', 'PIM', 'SH%']\n",
    "\n",
    "df = pd.DataFrame(acha_dynamic_stats, columns=column_names)\n",
    "df['Team'] = df['Team'].str.replace('WD2', 'WD1')\n",
    "#Skip every other row, keeping only odd-indexed rows \n",
    "df = df.iloc[::2]\n",
    "df = df[df['GP'].notna()]\n",
    "\n",
    "#Handle Jersey#, SHG, and PIM to keep NA values as NA\n",
    "for col in ['Jersey#', 'SHG', 'PIM']:\n",
    "    df[col] = df[col].apply(lambda x: int(float(x)) if x else pd.NA)\n",
    "\n",
    "#Reset the index to re-index the rows\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Convert specified columns to Int64 to handle nullable integers\n",
    "for col in ['Jersey#', 'SHG', 'PIM']:\n",
    "    df[col] = df[col].astype('Int64')\n",
    "\n",
    "numeric_columns = ['GP', 'G', 'A', 'PTS', 'Pt/G', 'PPG', 'GWG', 'SOGW', 'SH%']\n",
    "for column in numeric_columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')  \n",
    "\n",
    "string_columns = ['Name', 'Pos', 'Division', 'Team']\n",
    "for column in string_columns:\n",
    "    df[column] = df[column].astype(str)\n",
    "\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "df.to_csv('acha_wd1_skaters.csv', index=False)\n",
    "\n",
    "#Null values reflect website"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
