{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0fd820c-5f7e-4e97-8a0d-ceacafbbc271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Jersey#                Name Pos         Division  \\\n",
      "0          16         Ellie Schau   F          WD2 CHE   \n",
      "1          24    Nicole Partridge   F        WD2 IWCHL   \n",
      "2          24        Sam Sitterly   F  WD2 Independent   \n",
      "3          91   Sophia Buckberger   F        WD2 CCWHA   \n",
      "4           7       Camryn Browne   F        WD2 DVCHC   \n",
      "...       ...                 ...  ..              ...   \n",
      "1423        7    Shannon O'Conner   F        WD2 CCWHA   \n",
      "1424       30         Rachel Hart   G        WD2 CCWHA   \n",
      "1425       21        Kayla Obrien   D          WD2 CHE   \n",
      "1426       31    Samantha Steciak   G        WD2 CCWHA   \n",
      "1427       43  Sophia Kaplunovich   D        WD2 DVCHC   \n",
      "\n",
      "                                       Team  GP   G   A  PTS  Pt/G  PPG  SHG  \\\n",
      "0                 WD2 Mercyhurst University  13  29  12   41  3.15    1    3   \n",
      "1               WD2 Sacred Heart University  12  24  12   36  3.00    7    0   \n",
      "2           WD2 Eastern Michigan University  10  17  17   34  3.40    3    2   \n",
      "3     WD2 Lawrence Technological University  18  21  12   33  1.83    2    0   \n",
      "4                  WD2 Villanova University  15  14  19   33  2.20    0    0   \n",
      "...                                     ...  ..  ..  ..  ...   ...  ...  ...   \n",
      "1423     WD2 Bowling Green State University  13   0   0    0  0.00    0    0   \n",
      "1424  WD2 Lawrence Technological University  14   0   0    0  0.00    0    0   \n",
      "1425              WD2 Mercyhurst University  14   0   0    0  0.00    0    0   \n",
      "1426                  WD2 Aurora University  14   0   0    0  0.00    0    0   \n",
      "1427             WD2 University of Delaware  15   0   0    0  0.00    0    0   \n",
      "\n",
      "      GWG  SOGW  PIM  SH%  \n",
      "0       3     0   10  0.0  \n",
      "1       2     0   16  0.0  \n",
      "2       2     0    4  0.0  \n",
      "3       4     0   32  0.0  \n",
      "4       1     0    8  0.0  \n",
      "...   ...   ...  ...  ...  \n",
      "1423    0     0    4  0.0  \n",
      "1424    0     0    2  0.0  \n",
      "1425    0     0   16  0.0  \n",
      "1426    0     0    0  0.0  \n",
      "1427    0     0    0  0.0  \n",
      "\n",
      "[1428 rows x 16 columns]\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1428 entries, 0 to 1427\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Jersey#   1302 non-null   Int64  \n",
      " 1   Name      1428 non-null   object \n",
      " 2   Pos       1428 non-null   object \n",
      " 3   Division  1428 non-null   object \n",
      " 4   Team      1428 non-null   object \n",
      " 5   GP        1428 non-null   int64  \n",
      " 6   G         1428 non-null   int64  \n",
      " 7   A         1428 non-null   int64  \n",
      " 8   PTS       1428 non-null   int64  \n",
      " 9   Pt/G      1428 non-null   float64\n",
      " 10  PPG       1428 non-null   int64  \n",
      " 11  SHG       1302 non-null   Int64  \n",
      " 12  GWG       1428 non-null   int64  \n",
      " 13  SOGW      1428 non-null   int64  \n",
      " 14  PIM       1302 non-null   Int64  \n",
      " 15  SH%       1428 non-null   float64\n",
      "dtypes: Int64(3), float64(2), int64(7), object(4)\n",
      "memory usage: 182.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_acha_dynamic_stats():\n",
    "    firefox_options = Options()\n",
    "    firefox_options.add_argument(\"--headless\")  \n",
    "\n",
    "    geckodriver_path = r\"C:\\Program Files\\GeckoDriver\\geckodriver.exe\"\n",
    "    service = Service(executable_path=geckodriver_path)\n",
    "\n",
    "    with webdriver.Firefox(service=service, options=firefox_options) as driver:\n",
    "        url = \"https://www.achahockey.org/stats/player-stats/all-teams/45?conference=12&division=-1&playertype=skater&position=skaters&rookie=no&sort=points&statstype=standard&page=1&league=1\"\n",
    "        driver.get(url)\n",
    "\n",
    "        all_data = []\n",
    "        \n",
    "        while True:\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"table\")))\n",
    "            \n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            table = soup.find('table')\n",
    "            if table:\n",
    "                rows = table.find_all('tr')\n",
    "                for i, row in enumerate(rows[1:], start=1):  \n",
    "                    cols = row.find_all('td')\n",
    "                    cols = [ele.text.strip() for i, ele in enumerate(cols) if i != 0 and i != 2 and i != len(cols) - 1]\n",
    "                    all_data.append(cols)\n",
    "\n",
    "            try:\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//a[contains(text(), 'Next')]\"))\n",
    "                )\n",
    "                next_button.click()\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "acha_dynamic_stats = scrape_acha_dynamic_stats()\n",
    "\n",
    "column_names = ['Jersey#', 'Name', 'Pos', 'Division', 'Team', 'GP', 'G', 'A', 'PTS', 'Pt/G', 'PPG', 'SHG', 'GWG', 'SOGW', 'PIM', 'SH%']\n",
    "\n",
    "df = pd.DataFrame(acha_dynamic_stats, columns=column_names)\n",
    "\n",
    "#Skip every other row, keeping only odd-indexed rows \n",
    "df = df.iloc[::2]\n",
    "df = df[df['GP'].notna()]\n",
    "\n",
    "#Handle Jersey#, SHG, and PIM to keep NA values as NA\n",
    "for col in ['Jersey#', 'SHG', 'PIM']:\n",
    "    df[col] = df[col].apply(lambda x: int(float(x)) if x else pd.NA)\n",
    "\n",
    "#Reset the index to re-index the rows\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Convert specified columns to Int64 to handle nullable integers\n",
    "for col in ['Jersey#', 'SHG', 'PIM']:\n",
    "    df[col] = df[col].astype('Int64')\n",
    "\n",
    "numeric_columns = ['GP', 'G', 'A', 'PTS', 'Pt/G', 'PPG', 'GWG', 'SOGW', 'SH%']\n",
    "for column in numeric_columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')  \n",
    "\n",
    "string_columns = ['Name', 'Pos', 'Division', 'Team']\n",
    "for column in string_columns:\n",
    "    df[column] = df[column].astype(str)\n",
    "\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "df.to_csv('acha_wd2_skaters.csv', index=False)\n",
    "\n",
    "#Null values reflect website"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
